/* Copyright (c) 2016 Philip Taylor
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and/or associated documentation files (the "Materials"), to
 * deal in the Materials without restriction, including without limitation the
 * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 * sell copies of the Materials, and to permit persons to whom the Materials
 * are furnished to do so, subject to the following conditions:
 *
 * The above copyright notice(s) and this permission notice shall be included
 * in all copies or substantial portions of the Materials.
 *
 * THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 *
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
 * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE
 * USE OR OTHER DEALINGS IN THE MATERIALS
 */

#define NOMINMAX

#include "sync.h"

#include <algorithm>
#include <deque>
#include <sstream>

#define _LOG_GENERIC(level, objType, object, messageCode, fmt, ...) \
    log_msg(mReportData, level, \
        VK_DEBUG_REPORT_OBJECT_TYPE_##objType##_EXT, (uint64_t)(object), \
        __LINE__, (messageCode), "SYNC", (fmt), __VA_ARGS__)

#define LOG_INFO(objType, object, messageCode, fmt, ...)  _LOG_GENERIC(VK_DEBUG_REPORT_INFORMATION_BIT_EXT,         objType, object, messageCode, fmt, __VA_ARGS__)
#define LOG_WARN(objType, object, messageCode, fmt, ...)  _LOG_GENERIC(VK_DEBUG_REPORT_WARNING_BIT_EXT,             objType, object, messageCode, fmt, __VA_ARGS__)
#define LOG_PERF(objType, object, messageCode, fmt, ...)  _LOG_GENERIC(VK_DEBUG_REPORT_PERFORMANCE_WARNING_BIT_EXT, objType, object, messageCode, fmt, __VA_ARGS__)
#define LOG_ERROR(objType, object, messageCode, fmt, ...) _LOG_GENERIC(VK_DEBUG_REPORT_ERROR_BIT_EXT,               objType, object, messageCode, fmt, __VA_ARGS__)
#define LOG_DEBUG(objType, object, messageCode, fmt, ...) _LOG_GENERIC(VK_DEBUG_REPORT_DEBUG_BIT_EXT,               objType, object, messageCode, fmt, __VA_ARGS__)

/*
 * For each command submitted:
 *   Assign command ID = (queue ID, subpass ID, unique ID++)
 *   Construct nodes (cmdId, stage), (cmdId, SRC, stage), etc - store them in a hash set
 *     Actually we don't explicitly need them? they're implicit in the edges
 *   Construct memory nodes (READ|WRITE|FLUSH|INVALIDATE, cmdId, stage, access, mem)
 *
 * For pipeline barriers:
 *   Store a collection of edges:
 *     (upper-bound cmd ID, srcStage) < (barrier cmd ID, SRC, srcStage)
 *     (barrier cmd ID, DST, dstStage) < (lower-bound cmd ID, srcStage)
 *
 *  The bounded cmd IDs include queue ID (exact match), subpass ID (exact match, sorta), "<" or ">" some unique ID
 *  Also need "~" edges - maybe each edge has a cost, '<' is 1, '~' is 0
 *   - or maybe store '<=', and for '~' store both ways round
 *
 *  We need to answer queries like:
 *
 *    For every pair of overlapping memory accesses:
 *      Is W < R?
 *      Is R < W?
 *      Is W < F < I < R?
 *   If these fail we've got a race condition
 *   Print details about the write, and the read
 *
 *   A<B is just a graph search: maintain open, closed sets,
 *   be careful that some edges are implicitly generated by bounded IDs
 *
 */

#define CMP(a, b) do { if (a < b) return true; if (b < a) return false; } while (0)

CommandId::CommandId() : queueId(0), subpassId(0), sequenceId(0) { }

bool CommandId::operator<(const CommandId &c) const
{
    CMP(queueId, c.queueId);
    CMP(subpassId, c.subpassId);
    CMP(sequenceId, c.sequenceId);
    return false;
}

MemRegion::MemRegion() : type(INVALID),
    buffer(VK_NULL_HANDLE), bufferOffset(0), bufferRange(0),
    image(VK_NULL_HANDLE), imageSubresourceRange()
{
}

bool MemRegion::operator<(const MemRegion &m) const
{
    CMP(type, m.type);
    CMP(buffer, m.buffer);
    CMP(bufferOffset, m.bufferOffset);
    CMP(bufferRange, m.bufferRange);
    CMP(image, m.image);
    CMP(imageSubresourceRange.aspectMask, m.imageSubresourceRange.aspectMask);
    CMP(imageSubresourceRange.baseMipLevel, m.imageSubresourceRange.baseMipLevel);
    CMP(imageSubresourceRange.levelCount, m.imageSubresourceRange.levelCount);
    CMP(imageSubresourceRange.baseArrayLayer, m.imageSubresourceRange.baseArrayLayer);
    CMP(imageSubresourceRange.layerCount, m.imageSubresourceRange.layerCount);
    return false;
}

void MemRegion::to_string(std::ostream &str) const
{
    str << "{";

    switch (type)
    {
    case INVALID:
        str << " INVALID";
        break;
    case GLOBAL:
        str << " GLOBAL";
        break;
    case BUFFER:
        str << " BUFFER";
        str << " " << (void *)buffer;
        str << " offset=" << bufferOffset;
        str << " range=" << bufferRange;
        str << " deviceMemory=" << (void *)deviceMemory;
        str << " deviceMemoryOffset=" << deviceMemoryOffset;
        break;
    case IMAGE:
        str << " IMAGE";
        str << " " << (void *)image;
        str << " aspectMask=0x" << std::hex << imageSubresourceRange.aspectMask << std::dec;
        str << " baseMipLevel=" << imageSubresourceRange.baseMipLevel;
        str << " levelCount=" << imageSubresourceRange.levelCount;
        str << " baseArrayLayer=" << imageSubresourceRange.baseArrayLayer;
        str << " layerCount=" << imageSubresourceRange.layerCount;
        str << " deviceMemory=" << (void *)deviceMemory;
        str << " deviceMemoryOffset=" << deviceMemoryOffset;
        break;
    case SWAPCHAIN_IMAGE:
        str << " SWAPCHAIN_IMAGE";
        str << " " << (void *)image;
        str << " aspectMask=0x" << std::hex << imageSubresourceRange.aspectMask << std::dec;
        str << " baseMipLevel=" << imageSubresourceRange.baseMipLevel;
        str << " levelCount=" << imageSubresourceRange.levelCount;
        str << " baseArrayLayer=" << imageSubresourceRange.baseArrayLayer;
        str << " layerCount=" << imageSubresourceRange.layerCount;
        break;
    }

    str << " }";
}

static const VkPipelineStageFlagBits VIRTUAL_PIPELINE_STAGE_TRANSITION_BIT = (VkPipelineStageFlagBits)0x10000000;
static const VkAccessFlagBits VIRTUAL_ACCESS_TRANSITION_BIT = (VkAccessFlagBits)0x10000000;

static void stage_to_string(std::ostream &str, VkPipelineStageFlagBits stage)
{
    switch (stage)
    {
#define X(n) case VK_PIPELINE_STAGE_##n##_BIT: str << #n; break;
    X(TOP_OF_PIPE);
    X(DRAW_INDIRECT);
    X(VERTEX_INPUT);
    X(VERTEX_SHADER);
    X(TESSELLATION_CONTROL_SHADER);
    X(TESSELLATION_EVALUATION_SHADER);
    X(GEOMETRY_SHADER);
    X(FRAGMENT_SHADER);
    X(EARLY_FRAGMENT_TESTS);
    X(LATE_FRAGMENT_TESTS);
    X(COLOR_ATTACHMENT_OUTPUT);
    X(COMPUTE_SHADER);
    X(TRANSFER);
    X(BOTTOM_OF_PIPE);
    X(HOST);
#undef X
    case VIRTUAL_PIPELINE_STAGE_TRANSITION_BIT: str << "TRANSITION"; break;
    default: str << std::hex << stage << std::dec; break;
    }
}

static void access_to_string(std::ostream &str, VkAccessFlagBits access)
{
    switch (access)
    {
#define X(n) case VK_ACCESS_##n##_BIT: str << #n; break;
    X(INDIRECT_COMMAND_READ);
    X(INDEX_READ);
    X(VERTEX_ATTRIBUTE_READ);
    X(UNIFORM_READ);
    X(INPUT_ATTACHMENT_READ);
    X(SHADER_READ);
    X(SHADER_WRITE);
    X(COLOR_ATTACHMENT_READ);
    X(COLOR_ATTACHMENT_WRITE);
    X(DEPTH_STENCIL_ATTACHMENT_READ);
    X(DEPTH_STENCIL_ATTACHMENT_WRITE);
    X(TRANSFER_READ);
    X(TRANSFER_WRITE);
    X(HOST_READ);
    X(HOST_WRITE);
    X(MEMORY_READ);
    X(MEMORY_WRITE);
#undef X
    case VIRTUAL_ACCESS_TRANSITION_BIT: str << "TRANSITION"; break;
    default: str << std::hex << access << std::dec; break;
    }
}

void SyncCacheState::to_string(std::ostream &str)
{
    str << "{";

    switch (type)
    {
    case UNINITIALIZED:
        str << " UNINITIALIZED";
        break;
    case DIRTY:
        str << " DIRTY";
        break;
    case CLEAN:
        str << " CLEAN";
        break;
    }
    
    str << " memory=";
    memory.to_string(str);

    str << " writer=" << writer;
    str << " dirty={ ";
    stage_to_string(str, dirty.stage);
    str << " ";
    access_to_string(str, dirty.access);
    str << " }";

    str << " invalidated=[";

    for (auto &sa : invalidated)
    {
        str << " { ";
        stage_to_string(str, sa.stage);
        str << " ";
        access_to_string(str, sa.access);
        str << " }";
    }

    str << " ]";
    str << " }";
}

static bool findSubresourceRangeOverlap(const VkImageSubresourceRange &a, const VkImageSubresourceRange &b, VkImageSubresourceRange &overlap)
{
    if ((a.aspectMask & b.aspectMask) == 0)
        return false;

    overlap.aspectMask = a.aspectMask & b.aspectMask;

    if (a.baseMipLevel + a.levelCount <= b.baseMipLevel)
        return false;
    if (b.baseMipLevel + b.levelCount <= a.baseMipLevel)
        return false;

    overlap.baseMipLevel = std::max(a.baseMipLevel, b.baseMipLevel);
    overlap.levelCount = std::min(a.baseMipLevel + a.levelCount, b.baseMipLevel + b.levelCount) - overlap.baseMipLevel;

    if (a.baseArrayLayer + a.layerCount <= b.baseArrayLayer)
        return false;
    if (b.baseArrayLayer + b.layerCount <= a.baseArrayLayer)
        return false;

    overlap.baseArrayLayer = std::max(a.baseArrayLayer, b.baseArrayLayer);
    overlap.layerCount = std::min(a.baseArrayLayer + a.layerCount, b.baseArrayLayer + b.layerCount) - overlap.baseArrayLayer;

    return true;
}

static bool findSubresourceRangeOverlap2(const VkImageSubresourceRange &a, const VkImageSubresourceRange &b,
    VkImageSubresourceRange &overlap, std::vector<VkImageSubresourceRange> &diffs)
{
    if ((a.aspectMask & b.aspectMask) == 0)
        return false;

    overlap.aspectMask = a.aspectMask & b.aspectMask;

    if (a.aspectMask & ~b.aspectMask)
    {
        VkImageSubresourceRange diff = a;
        diff.aspectMask &= ~b.aspectMask;
        diffs.push_back(diff);
    }

    if (a.baseMipLevel + a.levelCount <= b.baseMipLevel)
        return false;
    if (b.baseMipLevel + b.levelCount <= a.baseMipLevel)
        return false;

    overlap.baseMipLevel = std::max(a.baseMipLevel, b.baseMipLevel);
    overlap.levelCount = std::min(a.baseMipLevel + a.levelCount, b.baseMipLevel + b.levelCount) - overlap.baseMipLevel;

    if (a.baseMipLevel < overlap.baseMipLevel)
    {
        VkImageSubresourceRange diff = a;
        diff.aspectMask = overlap.aspectMask;
        diff.baseMipLevel = a.baseMipLevel;
        diff.levelCount = overlap.baseMipLevel - a.baseMipLevel;
        diffs.push_back(diff);
    }

    if (a.baseMipLevel + a.levelCount > overlap.baseMipLevel + overlap.levelCount)
    {
        VkImageSubresourceRange diff = a;
        diff.aspectMask = overlap.aspectMask;
        diff.baseMipLevel = overlap.baseMipLevel + overlap.levelCount;
        diff.levelCount = a.baseMipLevel + a.levelCount - diff.baseMipLevel;
        diffs.push_back(diff);
    }

    if (a.baseArrayLayer + a.layerCount <= b.baseArrayLayer)
        return false;
    if (b.baseArrayLayer + b.layerCount <= a.baseArrayLayer)
        return false;

    overlap.baseArrayLayer = std::max(a.baseArrayLayer, b.baseArrayLayer);
    overlap.layerCount = std::min(a.baseArrayLayer + a.layerCount, b.baseArrayLayer + b.layerCount) - overlap.baseArrayLayer;

    if (a.baseArrayLayer < overlap.baseArrayLayer)
    {
        VkImageSubresourceRange diff = a;
        diff.aspectMask = overlap.aspectMask;
        diff.baseMipLevel = overlap.baseMipLevel;
        diff.levelCount = overlap.levelCount;
        diff.baseArrayLayer = a.baseArrayLayer;
        diff.layerCount = overlap.baseArrayLayer - a.baseArrayLayer;
        diffs.push_back(diff);
    }

    if (a.baseArrayLayer + a.layerCount > overlap.baseArrayLayer + overlap.layerCount)
    {
        VkImageSubresourceRange diff = a;
        diff.aspectMask = overlap.aspectMask;
        diff.baseMipLevel = overlap.baseMipLevel;
        diff.levelCount = overlap.levelCount;
        diff.baseArrayLayer = overlap.baseArrayLayer + overlap.layerCount;
        diff.layerCount = a.baseArrayLayer + a.layerCount - diff.baseArrayLayer;
        diffs.push_back(diff);
    }

    return true;
}

static bool findMemRegionOverlap(const MemRegion &a, const MemRegion &b, MemRegion &overlap)
{
    // Global overlaps with anything
    if (a.type == MemRegion::GLOBAL)
    {
        overlap = b;
        return true;
    }
    if (b.type == MemRegion::GLOBAL)
    {
        overlap = a;
        return true;
    }

    // Swapchain images can't be aliased, so we just need to check identity
    if (a.type == MemRegion::SWAPCHAIN_IMAGE && b.type == MemRegion::SWAPCHAIN_IMAGE)
    {
        overlap = a;
        if (a.image == b.image && findSubresourceRangeOverlap(a.imageSubresourceRange, b.imageSubresourceRange, overlap.imageSubresourceRange))
        {
            return true;
        }
        else
        {
            return false;
        }
    }

    if (a.type == MemRegion::IMAGE && b.type == MemRegion::IMAGE)
    {
        overlap = a;
        if (a.image == b.image && findSubresourceRangeOverlap(a.imageSubresourceRange, b.imageSubresourceRange, overlap.imageSubresourceRange))
        {
            return true;
        }
        else
        {
            // XXX: handle IMAGE aliasing
            return false;
        }
    }

    // TODO: handle BUFFER

    return false;
}

// Returns (a intersect b), (a - b)
static bool findMemRegionOverlap2(const MemRegion &a, const MemRegion &b,
    std::vector<MemRegion> &isct, std::vector<MemRegion> &diff)
{
    // Global overlaps with anything
    if (a.type == MemRegion::GLOBAL)
    {
        assert(0); // can't do diffs this way
        isct.push_back(b);
        return true;
    }
    if (b.type == MemRegion::GLOBAL)
    {
        isct.push_back(a);
        return true;
    }

    // Swapchain images can't be aliased, so we just need to check identity
    if (a.type == MemRegion::SWAPCHAIN_IMAGE && b.type == MemRegion::SWAPCHAIN_IMAGE)
    {
        if (a.image != b.image)
        {
            diff.push_back(a);
            return false;
        }
        MemRegion overlap = a;
        std::vector<VkImageSubresourceRange> rangeDiffs;
        if (findSubresourceRangeOverlap2(a.imageSubresourceRange, b.imageSubresourceRange, overlap.imageSubresourceRange, rangeDiffs))
            isct.push_back(overlap);

        for (auto &d : rangeDiffs)
        {
            MemRegion regionDiff = a;
            regionDiff.imageSubresourceRange = d;
            diff.push_back(regionDiff);
        }
        return !isct.empty();
    }

    if (a.type == MemRegion::IMAGE && b.type == MemRegion::IMAGE)
    {
        if (a.image != b.image)
        {
            diff.push_back(a);
            return false;
        }
        MemRegion overlap = a;
        std::vector<VkImageSubresourceRange> rangeDiffs;
        if (findSubresourceRangeOverlap2(a.imageSubresourceRange, b.imageSubresourceRange, overlap.imageSubresourceRange, rangeDiffs))
            isct.push_back(overlap);

        for (auto &d : rangeDiffs)
        {
            MemRegion regionDiff = a;
            regionDiff.imageSubresourceRange = d;
            diff.push_back(regionDiff);
        }
        return !isct.empty();

        // XXX: handle IMAGE aliasing
    }

    // TODO: handle BUFFER

    return false;
}

SyncNode::SyncNode() : type(INVALID), stages(0), accesses(0)
{
}

bool SyncNode::operator<(const SyncNode &n) const
{
    CMP(type, n.type);
    CMP(commandId, n.commandId);
    CMP(stages, n.stages);
    CMP(accesses, n.accesses);
    CMP(memory, n.memory);
    return false;
}

void SyncNode::to_string(std::ostream &str) const
{
    str << "{";

    str << " ";
    switch (type)
    {
    case INVALID: str << "INVALID"; break;
    case ACTION_CMD_STAGE_IN: str << "ACTION_CMD_STAGE_IN"; break;
    case ACTION_CMD_STAGE_OUT: str << "ACTION_CMD_STAGE_OUT"; break;
    case SYNC_CMD_SRC_STAGE: str << "SYNC_CMD_SRC_STAGE"; break;
    case SYNC_CMD_DST_STAGE: str << "SYNC_CMD_DST_STAGE"; break;
    case SYNC_CMD_SRC: str << "SYNC_CMD_SRC"; break;
    case SYNC_CMD_DST: str << "SYNC_CMD_DST"; break;
    case SYNC_CMD_POST_TRANS: str << "SYNC_CMD_POST_TRANS"; break;
    case SYNC_CMD_PRE_TRANS: str << "SYNC_CMD_PRE_TRANS"; break;
    case TRANSITION: str << "TRANSITION"; break;
    case MEM_READ: str << "MEM_READ"; break;
    case MEM_WRITE: str << "MEM_WRITE"; break;
    case MEM_FLUSH: str << "MEM_FLUSH"; break;
    case MEM_INVALIDATE: str << "MEM_INVALIDATE"; break;
    }

    str << " {";
    str << " queueId=" << commandId.queueId;
    if (commandId.subpassId == CommandId::SUBPASS_NONE)
        str << " subpassId=NONE";
    else
        str << " subpassId=" << commandId.queueId;
    str << " sequenceId=" << commandId.sequenceId;
    str << " }";

    switch (type)
    {
    case ACTION_CMD_STAGE_IN:
    case ACTION_CMD_STAGE_OUT:
    case SYNC_CMD_SRC_STAGE:
    case SYNC_CMD_DST_STAGE:
    case MEM_READ:
    case MEM_WRITE:
    case MEM_FLUSH:
    case MEM_INVALIDATE:
        str << " stages=[";

        for (VkFlags stage = 1; stage < 0x80000000; stage <<= 1)
        {
            if (stages & stage)
            {
                str << " ";
                stage_to_string(str, (VkPipelineStageFlagBits)stage);
            }
        }

        str << " ]";
        break;
    default:
        break;
    }

    switch (type)
    {
    case MEM_READ:
    case MEM_WRITE:
    case MEM_FLUSH:
    case MEM_INVALIDATE:
        str << " accesses=[";

        for (VkFlags access = 1; access < 0x80000000; access <<= 1)
        {
            if (accesses & access)
            {
                str << " ";
                access_to_string(str, (VkAccessFlagBits)access);
            }
        }

        str << " ] ";
        memory.to_string(str);
        break;

    default:
        break;
    }

    str << " }";
}

bool SyncEdge::operator<(const SyncEdge &e) const
{
    CMP(a, e.a);
    CMP(b, e.b);
    return false;
}

bool SyncEdgeSet::operator<(const SyncEdgeSet &e) const
{
    CMP(sync, e.sync);
    CMP(commandBound, e.commandBound);
    CMP(stage, e.stage);
    return false;
}

#undef CMP

template <typename T>
struct EnumIterator
{
    // (10,0) (5,1) -> 1<<1
    // (2,2) (1,3) -> 1<<3
    // (0,4) (0,5) (0,32) -> end

    struct It
    {
        T operator*() const
        {
            return static_cast<T>(1 << shift);
        }

        bool operator!=(const It &i) const
        {
            return !(value == i.value && shift == i.shift);
        }

        It &operator++()
        {
            ++shift;
            value >>= 1;
            while (shift < 32 && (value & 1) == 0)
            {
                ++shift;
                value >>= 1;
            }
            return *this;
        }

        It(VkFlags value, int shift) : value(value), shift(shift)
        {
            while (shift < 32 && (value & 1) == 0)
            {
                ++shift;
                value >>= 1;
            }
        }

    private:
        VkFlags value;
        int shift;
    };

    VkFlags initial;
    EnumIterator(VkFlags flags) : initial(flags) { }
    It begin() { return It(initial, 0); }
    It end() { return It(0, 32); }
};

// template <typename T>
// EnumIterator<T> MakeEnumIterator(T v) { return EnumIterator<T>(v); }

SyncValidator::SyncValidator(sync_device &syncDevice, debug_report_data *reportData)
    : mSyncDevice(syncDevice), mReportData(reportData)
{
    mNextNodeId = 0;
    mNextSubpassId = 0;

    mNextCommandId.queueId = 0;
    mNextCommandId.subpassId = CommandId::SUBPASS_NONE;
    mNextCommandId.sequenceId = 0;
}

bool SyncValidator::submitCmdBuffer(VkQueue queue, const sync_command_buffer& buf)
{
    // XXX: need mutex on mSyncDevice

    VkPipeline graphicsPipeline = VK_NULL_HANDLE;
    VkPipeline computePipeline = VK_NULL_HANDLE;

    struct Binding
    {
        sync_descriptor_set *descriptorSet;
        uint32_t dynamicOffset; // TODO
    };

    std::map<uint32_t, Binding> graphicsBindings;
    std::map<uint32_t, Binding> computeBindings;

    for (auto &cmd : buf.commands)
    {
        // TODO: reset state on vkCmdExecuteCommands

        if (cmd->as_begin_render_pass() || cmd->as_next_subpass())
        {
            mNextCommandId.subpassId = mNextSubpassId++;
        }

        if (cmd->as_end_render_pass())
        {
            mNextCommandId.subpassId = CommandId::SUBPASS_NONE;
        }

        auto bindPipeline = cmd->as_bind_pipeline();
        if (bindPipeline)
        {
            if (bindPipeline->pipelineBindPoint == VK_PIPELINE_BIND_POINT_GRAPHICS)
                graphicsPipeline = bindPipeline->pipeline;
            else if (bindPipeline->pipelineBindPoint == VK_PIPELINE_BIND_POINT_COMPUTE)
                computePipeline = bindPipeline->pipeline;
        }

        auto bindDescriptorSets = cmd->as_bind_descriptor_sets();
        if (bindDescriptorSets)
        {
            // TODO: should look at pipeline layout compatibility here
            // TODO: dynamic offsets

            for (uint32_t i = 0; i < bindDescriptorSets->descriptorSets.size(); ++i)
            {
                uint32_t setNumber = bindDescriptorSets->firstSet + i;

                auto descriptorSet = mSyncDevice.descriptor_sets.find(bindDescriptorSets->descriptorSets[i]);
                if (descriptorSet == mSyncDevice.descriptor_sets.end())
                {
                    return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                        "Draw command called with unknown descriptor set bound");
                }

                Binding binding;
                binding.descriptorSet = &descriptorSet->second;
                binding.dynamicOffset = 0;

                if (bindDescriptorSets->pipelineBindPoint == VK_PIPELINE_BIND_POINT_GRAPHICS)
                    graphicsBindings[setNumber] = binding;
                else if (bindDescriptorSets->pipelineBindPoint == VK_PIPELINE_BIND_POINT_COMPUTE)
                    computeBindings[setNumber] = binding;
            }
        }

        // XXX: handle vkCmdBindIndexBuffer

        if (cmd->as_pipeline_barrier())
        {
            auto pipelineBarrier = cmd->as_pipeline_barrier();

            CommandId commandId = mNextCommandId;
            mNextCommandId.sequenceId++;

            VkPipelineStageFlags normSrcStageMask;
            VkPipelineStageFlags normDstStageMask;

            const VkPipelineStageFlags graphicsStages =
                VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT |
                VK_PIPELINE_STAGE_VERTEX_INPUT_BIT |
                VK_PIPELINE_STAGE_VERTEX_SHADER_BIT |
                VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT |
                VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT |
                VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT |
                VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT |
                VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT |
                VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT |
                VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;

            const VkPipelineStageFlags commandStages =
                graphicsStages |
                VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT |
                VK_PIPELINE_STAGE_TRANSFER_BIT;

            normSrcStageMask = pipelineBarrier->srcStageMask & (
                VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT |
                VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT |
                VK_PIPELINE_STAGE_HOST_BIT |
                commandStages);

            if (pipelineBarrier->srcStageMask & VK_PIPELINE_STAGE_ALL_GRAPHICS_BIT)
                normSrcStageMask |= graphicsStages;
            if (pipelineBarrier->srcStageMask & VK_PIPELINE_STAGE_ALL_COMMANDS_BIT)
                normSrcStageMask |= commandStages;

            normDstStageMask = pipelineBarrier->dstStageMask & (
                VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT |
                VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT |
                VK_PIPELINE_STAGE_HOST_BIT |
                commandStages);

            if (pipelineBarrier->dstStageMask & VK_PIPELINE_STAGE_ALL_GRAPHICS_BIT)
                normDstStageMask |= graphicsStages;
            if (pipelineBarrier->dstStageMask & VK_PIPELINE_STAGE_ALL_COMMANDS_BIT)
                normDstStageMask |= commandStages;

            std::vector<uint64_t> srcStageNodeIds;
            for (auto stage : EnumIterator<VkPipelineStageFlagBits>(normSrcStageMask))
            {
                SyncNode srcStageNode;
                srcStageNode.type = SyncNode::SYNC_CMD_SRC_STAGE;
                srcStageNode.commandId = commandId;
                srcStageNode.stages = stage;

                uint64_t srcStageNodeId = addNode(srcStageNode);
                srcStageNodeIds.push_back(srcStageNodeId);

                mPrecedingEdges.insert(SyncEdgeSet(srcStageNodeId, commandId, stage));
            }

            std::vector<SyncNode> flushNodes, transNodes, invalidateNodes;

            for (auto &imgMemBarrier : pipelineBarrier->imageMemoryBarriers)
            {
                auto image = mSyncDevice.images.find(imgMemBarrier.image);
                if (image == mSyncDevice.images.end())
                {
                    return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                        "vkCmdPipelineBarrier called with image memory barrier with unknown image");
                }

                SyncNode srcMemNode;
                srcMemNode.type = SyncNode::MEM_FLUSH;
                srcMemNode.commandId = commandId;
                srcMemNode.memory.image = imgMemBarrier.image;
                srcMemNode.memory.imageSubresourceRange = imgMemBarrier.subresourceRange;
                srcMemNode.stages = pipelineBarrier->srcStageMask;
                srcMemNode.accesses = imgMemBarrier.srcAccessMask;

                SyncNode dstMemNode;
                dstMemNode.type = SyncNode::MEM_INVALIDATE;
                dstMemNode.commandId = commandId;
                dstMemNode.memory.image = imgMemBarrier.image;
                dstMemNode.memory.imageSubresourceRange = imgMemBarrier.subresourceRange;
                dstMemNode.stages = pipelineBarrier->dstStageMask;
                dstMemNode.accesses = imgMemBarrier.dstAccessMask;

                SyncNode transNode;
                transNode.type = SyncNode::MEM_WRITE;
                transNode.commandId = commandId;
                transNode.memory.image = imgMemBarrier.image;
                transNode.memory.imageSubresourceRange = imgMemBarrier.subresourceRange;
                transNode.stages = VIRTUAL_PIPELINE_STAGE_TRANSITION_BIT;
                transNode.accesses = VIRTUAL_ACCESS_TRANSITION_BIT;

                if (image->second.isSwapchain)
                {
                    srcMemNode.memory.type = MemRegion::SWAPCHAIN_IMAGE;
                    dstMemNode.memory.type = MemRegion::SWAPCHAIN_IMAGE;
                    transNode.memory.type = MemRegion::SWAPCHAIN_IMAGE;
                }
                else
                {
                    auto memory = mSyncDevice.device_memories.find(image->second.memory);
                    if (memory == mSyncDevice.device_memories.end())
                    {
                        return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                            "vkCmdPipelineBarrier called with image memory barrier with image with unknown memory");
                    }

                    srcMemNode.memory.type = MemRegion::IMAGE;
                    srcMemNode.memory.deviceMemory = memory->second.deviceMemory;
                    srcMemNode.memory.deviceMemoryOffset = image->second.memoryOffset;

                    dstMemNode.memory.type = MemRegion::IMAGE;
                    dstMemNode.memory.deviceMemory = memory->second.deviceMemory;
                    dstMemNode.memory.deviceMemoryOffset = image->second.memoryOffset;

                    transNode.memory.type = MemRegion::IMAGE;
                    transNode.memory.deviceMemory = memory->second.deviceMemory;
                    transNode.memory.deviceMemoryOffset = image->second.memoryOffset;
                }

                if (srcMemNode.accesses != 0)
                    flushNodes.push_back(srcMemNode);

                if (dstMemNode.accesses != 0)
                    invalidateNodes.push_back(dstMemNode);

                if (imgMemBarrier.newLayout != imgMemBarrier.oldLayout)
                    transNodes.push_back(transNode);
            }

            SyncNode srcNode, preTransNode, postTransNode, dstNode;

            srcNode.type = SyncNode::SYNC_CMD_SRC;
            preTransNode.type = SyncNode::SYNC_CMD_PRE_TRANS;
            postTransNode.type = SyncNode::SYNC_CMD_POST_TRANS;
            dstNode.type = SyncNode::SYNC_CMD_DST;

            srcNode.commandId = preTransNode.commandId = postTransNode.commandId = dstNode.commandId = commandId;

            uint64_t srcNodeId = addNode(srcNode);

            for (auto srcStageNodeId : srcStageNodeIds)
                mEdges.insert(SyncEdge(srcStageNodeId, srcNodeId));

            std::vector<uint64_t> flushNodeIds;
            for (SyncNode &node : flushNodes)
                flushNodeIds.push_back(addNode(node));

            uint64_t preTransNodeId = addNode(preTransNode);
            mEdges.insert(SyncEdge(srcNodeId, preTransNodeId));

            for (uint64_t flushNodeId : flushNodeIds)
            {
                mEdges.insert(SyncEdge(srcNodeId, flushNodeId));
                mEdges.insert(SyncEdge(flushNodeId, preTransNodeId));
            }

            std::vector<uint64_t> transNodeIds;
            for (SyncNode &node : transNodes)
                transNodeIds.push_back(addNode(node));

            uint64_t postTransNodeId = addNode(postTransNode);
            mEdges.insert(SyncEdge(preTransNodeId, postTransNodeId));

            for (uint64_t transNodeId : transNodeIds)
            {
                mEdges.insert(SyncEdge(preTransNodeId, transNodeId));
                mEdges.insert(SyncEdge(transNodeId, postTransNodeId));
            }

            std::vector<uint64_t> invalidateNodeIds;
            for (SyncNode &node : invalidateNodes)
                invalidateNodeIds.push_back(addNode(node));

            uint64_t dstNodeId = addNode(dstNode);
            mEdges.insert(SyncEdge(postTransNodeId, dstNodeId));

            for (uint64_t invalidateNodeId : invalidateNodeIds)
            {
                mEdges.insert(SyncEdge(postTransNodeId, invalidateNodeId));
                mEdges.insert(SyncEdge(invalidateNodeId, dstNodeId));
            }

            for (auto stage : EnumIterator<VkPipelineStageFlagBits>(normDstStageMask))
            {
                SyncNode dstStageNode;
                dstStageNode.type = SyncNode::SYNC_CMD_DST_STAGE;
                dstStageNode.commandId = commandId;
                dstStageNode.stages = stage;

                uint64_t dstStageNodeId = addNode(dstStageNode);

                mEdges.insert(SyncEdge(dstNodeId, dstStageNodeId));

                mFollowingEdges.insert(SyncEdgeSet(dstStageNodeId, commandId, stage));
            }
        }

        if (cmd->is_draw())
        {
            CommandId commandId = mNextCommandId;
            mNextCommandId.sequenceId++;

            if (graphicsPipeline == VK_NULL_HANDLE)
            {
                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                    "Draw command called with no pipeline bound");
            }

            auto pipeline = mSyncDevice.graphics_pipelines.find(graphicsPipeline);
            if (pipeline == mSyncDevice.graphics_pipelines.end())
            {
                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                    "Draw command called with unknown pipeline bound");
            }

            auto pipelineLayout = mSyncDevice.pipeline_layouts.find(pipeline->second.layout);
            if (pipelineLayout == mSyncDevice.pipeline_layouts.end())
            {
                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                    "Draw command called with pipeline with unknown pipeline layout");
            }

            std::stringstream str;
            str << "Draw command: ";
            cmd->to_string(str);
            str << "\n    Current pipeline:\n      ";
            pipeline->second.to_string(str);
            str << "\n    Current pipeline layout:\n      ";
            pipelineLayout->second.to_string(str);
            for (auto &setLayout : pipelineLayout->second.setLayouts)
            {
                auto set_layout = mSyncDevice.descriptor_set_layouts.find(setLayout);
                if (set_layout == mSyncDevice.descriptor_set_layouts.end())
                {
                    return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                        "Draw command called with pipeline layout with unknown descriptor set layout");
                }

                str << "\n        ";
                set_layout->second.to_string(str);
            }
            str << "\n    Current bindings:\n";
            for (auto &binding : graphicsBindings)
            {
                str << "      " << binding.first << ": ";
                binding.second.descriptorSet->to_string(str);
                str << "\n";
            }


            std::map<VkPipelineStageFlagBits, std::vector<SyncNode>> memNodes;

            str << "\n    Accessible memory:\n";
            uint32_t setIdx = 0;
            for (auto &setLayout : pipelineLayout->second.setLayouts)
            {
                auto layout = mSyncDevice.descriptor_set_layouts.find(setLayout);
                if (layout == mSyncDevice.descriptor_set_layouts.end())
                {
                    return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                        "Draw command called with pipeline layout with unknown descriptor set layout");
                }

                auto currentBinding = graphicsBindings.find(setIdx);
                if (currentBinding == graphicsBindings.end())
                {
                    return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                        "Draw command called with no descriptor set bound on set %u", setIdx);
                }

                uint32_t bindingIdx = 0;
                for (auto &binding : layout->second.bindings)
                {
                    auto currentDescriptor = currentBinding->second.descriptorSet->bindings.find(bindingIdx);
                    if (currentDescriptor == currentBinding->second.descriptorSet->bindings.end())
                    {
                        return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                            "Draw command called with no descriptor bound on set %u, binding %u", setIdx, bindingIdx);
                    }

                    // TODO: should check this is compatible, valid, etc

                    std::vector<VkPipelineStageFlagBits> pipelineStages;
                    if (binding.stageFlags & VK_SHADER_STAGE_VERTEX_BIT)
                        pipelineStages.push_back(VK_PIPELINE_STAGE_VERTEX_SHADER_BIT);
                    if (binding.stageFlags & VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT)
                        pipelineStages.push_back(VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT);
                    if (binding.stageFlags & VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT)
                        pipelineStages.push_back(VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT);
                    if (binding.stageFlags & VK_SHADER_STAGE_GEOMETRY_BIT)
                        pipelineStages.push_back(VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT);
                    if (binding.stageFlags & VK_SHADER_STAGE_FRAGMENT_BIT)
                        pipelineStages.push_back(VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT);
                    // TODO: should limit this to stages where the SPIR-V actually uses these descriptors

                    str << "      Set " << setIdx << ", binding " << bindingIdx << ", stageFlags 0x" << std::hex << binding.stageFlags << std::dec << ":\n";
                    for (uint32_t arrayIdx = 0; arrayIdx < binding.descriptorCount; ++arrayIdx)
                    {
                        str << "        [" << arrayIdx << "]";
                        switch (binding.descriptorType)
                        {
                        case VK_DESCRIPTOR_TYPE_SAMPLER:
                        case VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER:
                        case VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE:
                        case VK_DESCRIPTOR_TYPE_STORAGE_IMAGE:
                        case VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT:
                        {
                            auto &imageInfo = currentDescriptor->second.descriptors.at(arrayIdx).imageInfo;
                            auto imageView = mSyncDevice.image_views.find(imageInfo.imageView);
                            if (imageView == mSyncDevice.image_views.end())
                            {
                                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                                    "Draw command called with unknown image view on set %u, binding %u", setIdx, bindingIdx);
                            }
                            auto image = mSyncDevice.images.find(imageView->second.image);
                            if (image == mSyncDevice.images.end())
                            {
                                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                                    "Draw command called with image view with unknown image on set %u, binding %u", setIdx, bindingIdx);
                            }
                            auto memory = mSyncDevice.device_memories.find(image->second.memory);
                            if (!image->second.isSwapchain && memory == mSyncDevice.device_memories.end())
                            {
                                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                                    "Draw command called with image with unknown memory on set %u, binding %u", setIdx, bindingIdx);
                            }
                            str << " memoryRequirements={";
                            str << " size=" << image->second.memoryRequirements.size;
                            str << " alignment=" << image->second.memoryRequirements.alignment;
                            str << " memoryTypeBits=0x" << std::hex << image->second.memoryRequirements.memoryTypeBits << std::dec;
                            str << " }";

                            str << " memory=" << (void *)image->second.memory;
                            str << " {";
                            if (image->second.isSwapchain)
                            {
                                str << " swapchain";
                            }
                            else
                            {
                                str << " uid=" << memory->second.uid;
                                str << " allocationSize=" << memory->second.allocationSize;
                                str << " memoryTypeIndex=" << memory->second.memoryTypeIndex;
                                if (memory->second.isMapped)
                                {
                                    str << " mapOffset=" << memory->second.mapOffset;
                                    str << " mapSize=" << memory->second.mapSize;
                                    str << " mapFlags=" << memory->second.mapFlags;
                                    str << " pMapData=" << memory->second.pMapData;
                                }
                                else
                                {
                                    str << " unmapped";
                                }
                            }
                            str << " }";

                            str << " memoryOffset=" << image->second.memoryOffset;
                            str << " subresource={";
                            str << " aspectMask=" << std::hex << imageView->second.subresourceRange.aspectMask << std::dec;
                            str << " baseMipLevel=" << imageView->second.subresourceRange.baseMipLevel;
                            str << " levelCount=" << imageView->second.subresourceRange.levelCount;
                            str << " baseArrayLayer=" << imageView->second.subresourceRange.baseArrayLayer;
                            str << " layerCount=" << imageView->second.subresourceRange.layerCount;
                            str << " }";

                            SyncNode node;
                            node.commandId = commandId;
                            node.memory.image = imageView->second.image;
                            node.memory.imageSubresourceRange = imageView->second.subresourceRange;
                            if (image->second.isSwapchain)
                            {
                                node.memory.type = MemRegion::SWAPCHAIN_IMAGE;
                            }
                            else
                            {
                                node.memory.type = MemRegion::IMAGE;
                                node.memory.deviceMemory = memory->second.deviceMemory;
                                node.memory.deviceMemoryOffset = image->second.memoryOffset;
                            }

                            for (auto stage : pipelineStages)
                            {
                                node.stages = stage;

                                // XXX: handle the access types

                                node.type = SyncNode::MEM_READ;
                                node.accesses = VK_ACCESS_SHADER_READ_BIT;
                                memNodes[stage].push_back(node);

                                if (binding.descriptorType == VK_DESCRIPTOR_TYPE_STORAGE_IMAGE)
                                {
                                    node.type = SyncNode::MEM_WRITE;
                                    node.accesses = VK_ACCESS_SHADER_WRITE_BIT;
                                    memNodes[stage].push_back(node);
                                }
                            }

                            break;
                        }
                        case VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER:
                        case VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER:
                        {
                            auto bufferView = mSyncDevice.buffer_views.find(currentDescriptor->second.descriptors.at(arrayIdx).bufferView);
                            if (bufferView == mSyncDevice.buffer_views.end())
                            {
                                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                                    "Draw command called with unknown buffer view on set %u, binding %u", setIdx, bindingIdx);
                            }
                            auto buffer = mSyncDevice.buffers.find(bufferView->second.buffer);
                            if (buffer == mSyncDevice.buffers.end())
                            {
                                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                                    "Draw command called with buffer view with unknown buffer on set %u, binding %u", setIdx, bindingIdx);
                            }
                            auto memory = mSyncDevice.device_memories.find(buffer->second.memory);
                            if (memory == mSyncDevice.device_memories.end())
                            {
                                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                                    "Draw command called with buffer with unknown memory on set %u, binding %u", setIdx, bindingIdx);
                            }
                            str << " memoryRequirements={";
                            str << " size=" << buffer->second.memoryRequirements.size;
                            str << " alignment=" << buffer->second.memoryRequirements.alignment;
                            str << " memoryTypeBits=0x" << std::hex << buffer->second.memoryRequirements.memoryTypeBits << std::dec;
                            str << " }";

                            str << " memory=" << (void *)buffer->second.memory;
                            str << " {";
                            str << " uid=" << memory->second.uid;
                            str << " allocationSize=" << memory->second.allocationSize;
                            str << " memoryTypeIndex=" << memory->second.memoryTypeIndex;
                            if (memory->second.isMapped)
                            {
                                str << " mapOffset=" << memory->second.mapOffset;
                                str << " mapSize=" << memory->second.mapSize;
                                str << " mapFlags=" << memory->second.mapFlags;
                                str << " pMapData=" << memory->second.pMapData;
                            }
                            else
                            {
                                str << " unmapped";
                            }
                            str << " }";

                            str << " memoryOffset=" << buffer->second.memoryOffset;
                            str << " size=" << buffer->second.size;
                            str << " offset=" << bufferView->second.offset;
                            str << " range=" << bufferView->second.range;

                            SyncNode node;
                            node.commandId = commandId;
                            node.memory.type = MemRegion::BUFFER;
                            node.memory.buffer = bufferView->second.buffer;
                            node.memory.bufferOffset = bufferView->second.offset;
                            node.memory.bufferRange = bufferView->second.range;
                            node.memory.deviceMemory = memory->second.deviceMemory;
                            node.memory.deviceMemoryOffset = buffer->second.memoryOffset;

                            for (auto stage : pipelineStages)
                            {
                                node.stages = stage;

                                // XXX: handle the access types properly
                                // (TODO: is UNIFORM_TEXEL_BUFFER using ACCESS_UNIFORM_READ?)

                                node.type = SyncNode::MEM_READ;
                                node.accesses = VK_ACCESS_SHADER_READ_BIT;
                                memNodes[stage].push_back(node);

                                if (binding.descriptorType == VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER)
                                {
                                    node.type = SyncNode::MEM_WRITE;
                                    node.accesses = VK_ACCESS_SHADER_WRITE_BIT;
                                    memNodes[stage].push_back(node);
                                }
                            }

                            break;
                        }
                        case VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER:
                        case VK_DESCRIPTOR_TYPE_STORAGE_BUFFER:
                        case VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC:
                        case VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC:
                        {
                            auto &bufferInfo = currentDescriptor->second.descriptors.at(arrayIdx).bufferInfo;
                            auto buffer = mSyncDevice.buffers.find(bufferInfo.buffer);
                            if (buffer == mSyncDevice.buffers.end())
                            {
                                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                                    "Draw command called with unknown buffer on set %u, binding %u", setIdx, bindingIdx);
                            }
                            auto memory = mSyncDevice.device_memories.find(buffer->second.memory);
                            if (memory == mSyncDevice.device_memories.end())
                            {
                                return LOG_ERROR(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                                    "Draw command called with buffer with unknown memory on set %u, binding %u", setIdx, bindingIdx);
                            }
                            str << " memoryRequirements={";
                            str << " size=" << buffer->second.memoryRequirements.size;
                            str << " alignment=" << buffer->second.memoryRequirements.alignment;
                            str << " memoryTypeBits=0x" << std::hex << buffer->second.memoryRequirements.memoryTypeBits << std::dec;
                            str << " }";

                            str << " memory=" << (void *)buffer->second.memory;
                            str << " {";
                            str << " uid=" << memory->second.uid;
                            str << " allocationSize=" << memory->second.allocationSize;
                            str << " memoryTypeIndex=" << memory->second.memoryTypeIndex;
                            if (memory->second.isMapped)
                            {
                                str << " mapOffset=" << memory->second.mapOffset;
                                str << " mapSize=" << memory->second.mapSize;
                                str << " mapFlags=" << memory->second.mapFlags;
                                str << " pMapData=" << memory->second.pMapData;
                            }
                            else
                            {
                                str << " unmapped";
                            }
                            str << " }";

                            str << " memoryOffset=" << buffer->second.memoryOffset;
                            str << " size=" << buffer->second.size;

                            SyncNode node;
                            node.commandId = commandId;
                            node.memory.type = MemRegion::BUFFER;
                            node.memory.buffer = bufferInfo.buffer;
                            node.memory.bufferOffset = bufferInfo.offset;
                            node.memory.bufferRange = bufferInfo.range;
                            node.memory.deviceMemory = memory->second.deviceMemory;
                            node.memory.deviceMemoryOffset = buffer->second.memoryOffset;

                            // XXX: handle pDynamicOffsets

                            for (auto stage : pipelineStages)
                            {
                                node.stages = stage;

                                // XXX: handle the access types properly

                                node.type = SyncNode::MEM_READ;
                                node.accesses = VK_ACCESS_SHADER_READ_BIT;
                                memNodes[stage].push_back(node);

                                if (binding.descriptorType == VK_DESCRIPTOR_TYPE_STORAGE_BUFFER || binding.descriptorType == VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC)
                                {
                                    node.type = SyncNode::MEM_WRITE;
                                    node.accesses = VK_ACCESS_SHADER_WRITE_BIT;
                                    memNodes[stage].push_back(node);
                                }
                            }

                            break;
                        }
                        default:
                            str << " (INVALID TYPE)";
                            break;
                        }
                        str << "\n";
                    }
                    ++bindingIdx;
                }

                ++setIdx;
            }


            {
                SyncNode topNode, inNode, outNode, bottomNode;
                topNode.type = inNode.type = SyncNode::ACTION_CMD_STAGE_IN;
                outNode.type = bottomNode.type = SyncNode::ACTION_CMD_STAGE_OUT;
                topNode.commandId = inNode.commandId = outNode.commandId = bottomNode.commandId = commandId;

                topNode.stages = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
                bottomNode.stages = VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT;

                uint64_t topNodeId = addNode(topNode);

                std::vector<uint64_t> outNodeIds;
                for (VkPipelineStageFlagBits stage : {
                    VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT,
                    VK_PIPELINE_STAGE_VERTEX_INPUT_BIT,
                    VK_PIPELINE_STAGE_VERTEX_SHADER_BIT,
                    VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT,
                    VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT,
                    VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT,
                    VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT,
                    VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT,
                    VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT,
                    VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT,
                    VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT,
                    VK_PIPELINE_STAGE_TRANSFER_BIT,
                })
                {
                    inNode.stages = outNode.stages = stage;
                    uint64_t inNodeId = addNode(inNode);

                    mEdges.insert(SyncEdge(topNodeId, inNodeId));

                    std::vector<uint64_t> memNodeIds;
                    for (SyncNode &memNode : memNodes[stage])
                        memNodeIds.push_back(addNode(memNode));

                    uint64_t outNodeId = addNode(outNode);
                    outNodeIds.push_back(outNodeId);

                    for (uint64_t memNodeId : memNodeIds)
                    {
                        mEdges.insert(SyncEdge(inNodeId, memNodeId));
                        mEdges.insert(SyncEdge(memNodeId, outNodeId));
                    }
                }

                uint64_t bottomNodeId = addNode(bottomNode);
                for (uint64_t outNodeId : outNodeIds)
                    mEdges.insert(SyncEdge(outNodeId, bottomNodeId));
            }

            if (LOG_INFO(COMMAND_BUFFER, buf.command_buffer, SYNC_MSG_NONE,
                "%s", str.str().c_str()))
                return true;
        }
    }

    for (auto &it : mNodesById)
    {
        std::stringstream str;
        it.second.to_string(str);
        if (LOG_INFO(QUEUE, queue, SYNC_MSG_NONE, "Mem node: %"PRIu64" %s", it.first, str.str().c_str()))
            return true;
    }

    for (const SyncEdge &edge : mEdges)
    {
        std::stringstream str;
        str << "    src: " << edge.a << " ";
        mNodesById[edge.a].to_string(str);
        str << "\n    dst: " << edge.b << " ";
        mNodesById[edge.b].to_string(str);
        if (LOG_INFO(QUEUE, queue, SYNC_MSG_NONE, "Edge:\n%s", str.str().c_str()))
            return true;
    }

    for (auto &it1 = mNodesById.begin(); it1 != mNodesById.end(); ++it1)
    {
        for (auto &it2 = mNodesById.begin(); it2 != mNodesById.end(); ++it2)
        {
            if (it1 == it2)
                continue;

            if (it1->second.type == SyncNode::MEM_WRITE && it2->second.type == SyncNode::MEM_READ)
            {
//                 std::stringstream str;
//                 str << "Write-and-read between\n  node " << it1->first << " ";
//                 it1->second.to_string(str);
//                 str << ";\n  node " << it2->first << " ";
//                 it2->second.to_string(str);
//                 if (LOG_INFO(QUEUE, queue, SYNC_MSG_NONE, "%s", str.str().c_str()))
//                     return true;

                MemRegion overlap;
                if (findMemRegionOverlap(it1->second.memory, it2->second.memory, overlap))
                {
                    std::stringstream str;
                    str << "Overlap between\n  node " << it1->first << " ";
                    it1->second.to_string(str);
                    str << ";\n  node " << it2->first << " ";
                    it2->second.to_string(str);
                    str << ";\n  overlap at ";
                    overlap.to_string(str);
                    if (LOG_INFO(QUEUE, queue, SYNC_MSG_NONE, "%s", str.str().c_str()))
                        return true;

                    bool path1 = findPath(it1->first, it2->first);
                    bool path2 = findPath(it2->first, it1->first);
                    if (LOG_INFO(QUEUE, queue, SYNC_MSG_NONE, "path1=%d path2=%d", path1, path2))
                        return true;
                    if ((path1 && path2) || (!path1 && !path2))
                    {
                        if (LOG_ERROR(QUEUE, queue, SYNC_MSG_NONE, "Write and read have no order between them"))
                            return true;
                    }
                }
            }
        }
    }

    // Each byte has state:
    //   (C) clean, not written
    //   (D) written by W1, dirty in S+A
    //   (F) written by W1, clean, invalidated in []
    //   (I) written by W1, clean, invalidated in [S1+A1, S2+A2, ...]
    // 
    // On write:
    //   C -> D
    //   D -> error (write while dirty)
    //   F -> error (write before invalidate/make-visible)
    //   I -> error if not invalidated in the right S+A; otherwise D (need to update marker of who last wrote it)
    // On read:
    //   C -> okay
    //   D,F -> error
    //   I -> error if not invalidated in the right S+A; otherwise ok
    // On flush:
    //   C -> C
    //   D -> F if the S+A match
    //   F -> F
    //   I -> I
    // On invalidate:
    //   C -> C
    //   D -> D
    //   F -> I
    //   I -> I
    // 
    // Each node needs to merge the states of its predecessors
    // If there are two different Ws: error, concurrent writes to overlapping memory
    // If they are the same: clean supersedes dirty, invalidated supersedes not

    {
        std::map<NodeId, std::vector<SyncCacheState>> cacheStates;

        for (auto &it : mNodesById)
        {
            NodeId nodeId = it.first;
            const SyncNode &node = it.second;

            std::vector<NodeId> preds = findPredecessors(nodeId);

            // Merge the states from all predecessors
            std::vector<SyncCacheState> mergedCacheStates;

            for (NodeId pred : preds)
            {
                for (auto &predState : cacheStates[pred])
                {
                    std::vector<SyncCacheState> appendedCacheStates;

                    // XXX: this is implemented all wrong
                    // 
                    // If predState overlaps with one of our existing merged states,
                    // we need split the merged state into intersection/diff and update
                    // them separately. Any part of predState that doesn't overlap any
                    // existing merged state then gets added unchanged.

                    bool added = false;
                    for (auto &currState : mergedCacheStates)
                    {
                        std::vector<MemRegion> iscts;
                        std::vector<MemRegion> iscts2; // XXX
                        std::vector<MemRegion> diffs1;
                        std::vector<MemRegion> diffs2;
                        if (findMemRegionOverlap2(predState.memory, currState.memory, iscts, diffs1))
                        {
                            added = true;

                            if (predState.writer != currState.writer)
                            {
                                if (LOG_ERROR(QUEUE, queue, SYNC_MSG_NONE, "Race between writes"))
                                    return true;
                            }
                            findMemRegionOverlap2(predState.memory, currState.memory, iscts2, diffs2);

                            for (auto &r : iscts)
                            {
                                SyncCacheState state;
                                state.memory = r;
                                state.writer = currState.writer;
                                if (predState.type == SyncCacheState::CLEAN || currState.type == SyncCacheState::CLEAN)
                                {
                                    state.type = SyncCacheState::CLEAN;
                                    state.dirty.stage = (VkPipelineStageFlagBits)0;
                                    state.dirty.access = (VkAccessFlagBits)0;
                                    state.invalidated = currState.invalidated;
                                    for (auto sa : predState.invalidated)
                                        state.invalidated.insert(sa);
                                }
                                else
                                {
                                    state.type = SyncCacheState::DIRTY;
                                    assert(predState.dirty.stage == currState.dirty.stage);
                                    assert(predState.dirty.access == currState.dirty.access);
                                    state.dirty = currState.dirty;
                                }
                                appendedCacheStates.push_back(state);
                            }
                            for (auto &r : diffs1)
                            {
                                SyncCacheState state = predState;
                                state.memory = r;
                                appendedCacheStates.push_back(state);
                            }
                            for (auto &r : diffs2)
                            {
                                SyncCacheState state = currState;
                                state.memory = r;
                                appendedCacheStates.push_back(state);
                            }
                        }
                        else
                        {
                            appendedCacheStates.push_back(currState);
                        }
                    }

                    if (!added)
                    {
                        appendedCacheStates.push_back(predState);
                    }

                    mergedCacheStates = appendedCacheStates;
                    //mergedCacheStates.insert(mergedCacheStates.end(), appendedCacheStates.begin(), appendedCacheStates.end());
                }
            }


            std::vector<SyncCacheState> newCacheStates;

            if (node.type == SyncNode::MEM_WRITE)
            {
                bool hasOverlap = false; // XXX
                for (auto &predState : mergedCacheStates)
                {
                    std::vector<MemRegion> iscts;
                    std::vector<MemRegion> diffs;
                    if (findMemRegionOverlap2(predState.memory, node.memory, iscts, diffs))
                    {
                        if (predState.type == SyncCacheState::DIRTY)
                        {
                            std::stringstream str;
                            str << "Write after write without flushing";
                            str << "\nAffected memory range: ";
                            iscts[0].to_string(str);
                            str << "\nFirst write instruction: ";
                            mNodesById[predState.writer].to_string(str);
                            str << "\nSecond write instruction: ";
                            node.to_string(str);
                            if (LOG_ERROR(QUEUE, queue, SYNC_MSG_NONE, "%s", str.str().c_str()))
                                return true;

                            if (LOG_ERROR(QUEUE, queue, SYNC_MSG_NONE, "Write after write without flushing"))
                                return true;
                        }
                        else if (predState.type == SyncCacheState::CLEAN)
                        {
                            bool isInvalidated = false;
                            for (auto &sa : predState.invalidated)
                            {
                                if ((sa.stage & node.stages) && (sa.access & node.accesses))
                                {
                                    isInvalidated = true;
                                }
                            }
                            if (!isInvalidated && !(node.stages == VIRTUAL_PIPELINE_STAGE_TRANSITION_BIT && node.accesses == VIRTUAL_ACCESS_TRANSITION_BIT))
                            {
                                if (LOG_ERROR(QUEUE, queue, SYNC_MSG_NONE, "Write after write without invalidating"))
                                    return true;
                            }
                        }
                        for (auto &r : iscts)
                        {
                            SyncCacheState newState;
                            newState.memory = r;
                            newState.writer = nodeId;
                            if (node.stages == VIRTUAL_PIPELINE_STAGE_TRANSITION_BIT && node.accesses == VIRTUAL_ACCESS_TRANSITION_BIT)
                            {
                                newState.type = SyncCacheState::CLEAN;
                                newState.dirty.stage = (VkPipelineStageFlagBits)0;
                                newState.dirty.access = (VkAccessFlagBits)0;
                            }
                            else
                            {
                                newState.type = SyncCacheState::DIRTY;
                                newState.dirty.stage = (VkPipelineStageFlagBits)node.stages;
                                newState.dirty.access = (VkAccessFlagBits)node.accesses;
                            }
                            newCacheStates.push_back(newState);
                        }
                        for (auto &r : diffs)
                        {
                            SyncCacheState newState = predState;
                            newState.memory = r;
                            newCacheStates.push_back(newState);
                        }

                        hasOverlap = true;
                    }
                    else
                    {
                        newCacheStates.push_back(predState);
                    }
                }
                if (!hasOverlap)
                {
                    SyncCacheState newState;
                    newState.memory = node.memory;
                    newState.writer = nodeId;
                    if (node.stages == VIRTUAL_PIPELINE_STAGE_TRANSITION_BIT && node.accesses == VIRTUAL_ACCESS_TRANSITION_BIT)
                    {
                        newState.type = SyncCacheState::CLEAN;
                        newState.dirty.stage = (VkPipelineStageFlagBits)0;
                        newState.dirty.access = (VkAccessFlagBits)0;
                    }
                    else
                    {
                        newState.type = SyncCacheState::DIRTY;
                        newState.dirty.stage = (VkPipelineStageFlagBits)node.stages;
                        newState.dirty.access = (VkAccessFlagBits)node.accesses;
                    }
                    newCacheStates = mergedCacheStates;
                    newCacheStates.push_back(newState);
                }
            }
            else if (node.type == SyncNode::MEM_READ)
            {
                for (auto &predState : mergedCacheStates)
                {
                    std::vector<MemRegion> iscts;
                    std::vector<MemRegion> diffs;
                    if (findMemRegionOverlap2(predState.memory, node.memory, iscts, diffs))
                    {
                        if (predState.type == SyncCacheState::DIRTY)
                        {
                            if (LOG_ERROR(QUEUE, queue, SYNC_MSG_NONE, "Read after write without flushing"))
                                return true;
                        }
                        else if (predState.type == SyncCacheState::CLEAN)
                        {
                            bool isInvalidated = false;
                            for (auto &sa : predState.invalidated)
                            {
                                if ((sa.stage & node.stages) && (sa.access & node.accesses))
                                {
                                    isInvalidated = true;
                                }
                            }
                            if (!isInvalidated)
                            {
                                std::stringstream str;
                                str << "Read after write without invalidating";
                                str << "\nAffected memory range: ";
                                iscts[0].to_string(str);
                                str << "\nWrite instruction: ";
                                mNodesById[predState.writer].to_string(str);
                                str << "\nRead instruction: ";
                                node.to_string(str);
                                str << "\n(This write has only been invalidated for these stageMask/accessMask combinations: [";
                                for (auto &sa : predState.invalidated)
                                {
                                    str << " { ";
                                    stage_to_string(str, sa.stage);
                                    str << " ";
                                    access_to_string(str, sa.access);
                                    str << " }";
                                }
                                str << " ])";
                                if (LOG_ERROR(QUEUE, queue, SYNC_MSG_NONE, "%s", str.str().c_str()))
                                    return true;

                                if (LOG_ERROR(QUEUE, queue, SYNC_MSG_NONE, "Read after write without invalidating"))
                                    return true;
                            }
                        }
                    }
                    newCacheStates.push_back(predState);
                }
            }
            else if (node.type == SyncNode::MEM_FLUSH)
            {
                for (auto &predState : mergedCacheStates)
                {
                    std::vector<MemRegion> iscts;
                    std::vector<MemRegion> diffs;
                    if (findMemRegionOverlap2(predState.memory, node.memory, iscts, diffs))
                    {
                        if (predState.type == SyncCacheState::DIRTY &&
                            (predState.dirty.stage & node.stages) && (predState.dirty.access & node.accesses))
                        {
                            SyncCacheState newState = predState;
                            newState.type = SyncCacheState::CLEAN;
                            newState.dirty.stage = (VkPipelineStageFlagBits)0;
                            newState.dirty.access = (VkAccessFlagBits)0;
                            newCacheStates.push_back(newState);
                        }
                        else
                        {
                            newCacheStates.push_back(predState);
                        }
                    }
                    else
                    {
                        newCacheStates.push_back(predState);
                    }
                }
            }
            else if (node.type == SyncNode::MEM_INVALIDATE)
            {
                for (auto &predState : mergedCacheStates)
                {
                    std::vector<MemRegion> iscts;
                    std::vector<MemRegion> diffs;
                    if (findMemRegionOverlap2(predState.memory, node.memory, iscts, diffs))
                    {
                        if (predState.type == SyncCacheState::CLEAN)
                        {
                            for (auto &r : iscts)
                            {
                                SyncCacheState newState = predState;
                                for (auto stage : EnumIterator<VkPipelineStageFlagBits>(node.stages))
                                {
                                    for (auto access : EnumIterator<VkAccessFlagBits>(node.accesses))
                                    {
                                        newState.invalidated.insert({ stage, access });
                                    }
                                }
                                newCacheStates.push_back(newState);
                            }
                            for (auto &r : diffs)
                            {
                                SyncCacheState newState = predState;
                                newState.memory = r;
                                newCacheStates.push_back(newState);
                            }
                        }
                        else
                        {
                            newCacheStates.push_back(predState);
                        }
                    }
                    else
                    {
                        newCacheStates.push_back(predState);
                    }
                }
            }
            else
            {
                newCacheStates = mergedCacheStates;
            }

            cacheStates[nodeId] = newCacheStates;

            std::stringstream str;
            str << "Node " << nodeId << ": ";
            node.to_string(str);
            str << "\n  Preds:";
            for (auto p : preds)
                str << " " << p;
            str << "\n  Input states:";
            for (auto &state : mergedCacheStates)
            {
                str << "\n    ";
                state.to_string(str);
            }
            str << "\n  Output states:";
            for (auto &state : newCacheStates)
            {
                str << "\n    ";
                state.to_string(str);
            }

            if (LOG_INFO(QUEUE, queue, SYNC_MSG_NONE,
                "%s", str.str().c_str()))
                return true;
        }
    }


    return false;
}

uint64_t SyncValidator::addNode(const SyncNode &node)
{
    auto it = mNodeIds.find(node);
    if (it != mNodeIds.end())
        return it->second;

    uint64_t id = mNextNodeId++;
    mNodesById[id] = node;
    mNodeIds[node] = id;
    return id;
}

// Return true if srcNodeId < dstNodeId
bool SyncValidator::findPath(uint64_t srcNodeId, uint64_t dstNodeId)
{
    std::deque<uint64_t> openList;
    std::set<uint64_t> closedSet;

    openList.push_back(srcNodeId);

    while (!openList.empty())
    {
        uint64_t curNodeId = openList.front();
        openList.pop_front();

        if (curNodeId == dstNodeId)
            return true;

        // Mark this node as closed, or if it was already closed then skip it
        bool inserted = closedSet.insert(curNodeId).second;
        if (!inserted)
            continue;

        SyncNode curNode = mNodesById[curNodeId];

        // Find every node N such that nodeId <= N, add them to the open list

        for (auto &edge : mEdges)
        {
            if (edge.a == curNodeId)
            {
                openList.push_back(edge.b);
            }
        }

        if (curNode.type == SyncNode::ACTION_CMD_STAGE_OUT || curNode.type == SyncNode::SYNC_CMD_DST_STAGE)
        {
            for (auto &edgeSet : mPrecedingEdges)
            {
                if (edgeSet.commandBound.queueId == curNode.commandId.queueId &&
                    (edgeSet.commandBound.subpassId == CommandId::SUBPASS_NONE ||
                        edgeSet.commandBound.subpassId == curNode.commandId.subpassId) &&
                    curNode.commandId.sequenceId < edgeSet.commandBound.sequenceId)
                {
                    assert(curNodeId < edgeSet.sync);
                    SyncNode syncNode = mNodesById[edgeSet.sync];
                    if ((curNode.stages & syncNode.stages) != 0)
                    {
                        openList.push_back(edgeSet.sync);
                    }
                }
            }
        }

        if (curNode.type == SyncNode::SYNC_CMD_DST_STAGE)
        {
            for (auto &edgeSet : mFollowingEdges)
            {
                if (edgeSet.sync == curNodeId)
                {
                    for (auto &otherNode : mNodesById)
                    {
                        if (edgeSet.commandBound.queueId == otherNode.second.commandId.queueId &&
                            (edgeSet.commandBound.subpassId == CommandId::SUBPASS_NONE ||
                                edgeSet.commandBound.subpassId == otherNode.second.commandId.subpassId) &&
                            edgeSet.commandBound.sequenceId < otherNode.second.commandId.sequenceId)
                        {
                            assert(edgeSet.sync < otherNode.first);
                            if (otherNode.second.type == SyncNode::ACTION_CMD_STAGE_IN || otherNode.second.type == SyncNode::SYNC_CMD_SRC_STAGE)
                            {
                                if ((curNode.stages & otherNode.second.stages) != 0)
                                {
                                    openList.push_back(otherNode.first);
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    return false;
}

std::vector<NodeId> SyncValidator::findPredecessors(NodeId curNodeId)
{
    std::set<NodeId> preds;

    const SyncNode &curNode = mNodesById[curNodeId];

    // Find every node N such that N < curNode, add them to the open list

    for (auto &edge : mEdges)
    {
        if (edge.b == curNodeId)
        {
            preds.insert(edge.a);
        }
    }

    if (curNode.type == SyncNode::SYNC_CMD_SRC_STAGE)
    {
        for (auto &edgeSet : mPrecedingEdges)
        {
            if (edgeSet.sync == curNodeId)
            {
                for (auto &otherNode : mNodesById)
                {
                    if (edgeSet.commandBound.queueId == otherNode.second.commandId.queueId &&
                        (edgeSet.commandBound.subpassId == CommandId::SUBPASS_NONE ||
                            edgeSet.commandBound.subpassId == otherNode.second.commandId.subpassId) &&
                        otherNode.second.commandId.sequenceId < edgeSet.commandBound.sequenceId)
                    {
                        assert(otherNode.first < edgeSet.sync);
                        if (otherNode.second.type == SyncNode::ACTION_CMD_STAGE_OUT || otherNode.second.type == SyncNode::SYNC_CMD_DST_STAGE)
                        {
                            if ((curNode.stages & otherNode.second.stages) != 0)
                            {
                                preds.insert(otherNode.first);
                            }
                        }
                    }
                }
            }
        }
    }

    if (curNode.type == SyncNode::ACTION_CMD_STAGE_IN || curNode.type == SyncNode::SYNC_CMD_SRC_STAGE)
    {
        for (auto &edgeSet : mFollowingEdges)
        {
            if (edgeSet.commandBound.queueId == curNode.commandId.queueId &&
                (edgeSet.commandBound.subpassId == CommandId::SUBPASS_NONE ||
                    edgeSet.commandBound.subpassId == curNode.commandId.subpassId) &&
                edgeSet.commandBound.sequenceId < curNode.commandId.sequenceId)
            {
                assert(edgeSet.sync < curNodeId);
                SyncNode syncNode = mNodesById[edgeSet.sync];
                if ((curNode.stages & syncNode.stages) != 0)
                {
                    preds.insert(edgeSet.sync);
                }
            }
        }
    }

    // Strip to minimal set:
    // For A,B: If A=B, push A; if A<B, push B

    std::set<NodeId> directPreds;
    for (NodeId a : preds)
    {
        bool skip = false;
        for (NodeId b : directPreds)
        {
            if (a == b)
            {
                skip = true;
                break;
            }
            if (findPath(a, b))
            {
                skip = true;
                break;
            }
            if (findPath(b, a))
            {
                directPreds.erase(b);
                break;
            }
        }
        if (!skip)
            directPreds.insert(a);
    }

    std::vector<NodeId> ret;
    for (NodeId a : directPreds)
        ret.push_back(a);
    return ret;
}
